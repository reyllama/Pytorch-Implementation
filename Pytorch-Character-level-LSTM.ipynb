{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.006348,
     "end_time": "2020-09-01T10:38:57.194050",
     "exception": false,
     "start_time": "2020-09-01T10:38:57.187702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-01T10:38:57.212388Z",
     "iopub.status.busy": "2020-09-01T10:38:57.211630Z",
     "iopub.status.idle": "2020-09-01T10:38:58.754326Z",
     "shell.execute_reply": "2020-09-01T10:38:58.755038Z"
    },
    "papermill": {
     "duration": 1.556064,
     "end_time": "2020-09-01T10:38:58.755209",
     "exception": false,
     "start_time": "2020-09-01T10:38:57.199145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA ON\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    print(\"CUDA ON\")\n",
    "else:\n",
    "    print('NO CUDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-01T10:38:58.771400Z",
     "iopub.status.busy": "2020-09-01T10:38:58.770816Z",
     "iopub.status.idle": "2020-09-01T10:38:58.862741Z",
     "shell.execute_reply": "2020-09-01T10:38:58.863256Z"
    },
    "papermill": {
     "duration": 0.102857,
     "end_time": "2020-09-01T10:38:58.863409",
     "exception": false,
     "start_time": "2020-09-01T10:38:58.760552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9626992"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = None\n",
    "for i in range(1,6):\n",
    "    with open(\"/kaggle/input/game-of-thrones-book-files/got{}.txt\".format(i), 'r') as f:\n",
    "        if text is None:\n",
    "            text = f.read()\n",
    "        else:\n",
    "            text += f.read()\n",
    "text = text.replace('\\n', '')\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.004991,
     "end_time": "2020-09-01T10:38:58.873800",
     "exception": false,
     "start_time": "2020-09-01T10:38:58.868809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T10:38:59.012830Z",
     "iopub.status.busy": "2020-09-01T10:38:59.011741Z",
     "iopub.status.idle": "2020-09-01T10:39:01.505795Z",
     "shell.execute_reply": "2020-09-01T10:39:01.506300Z"
    },
    "papermill": {
     "duration": 2.626066,
     "end_time": "2020-09-01T10:39:01.506432",
     "exception": false,
     "start_time": "2020-09-01T10:38:58.880366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74, 89, 47, 83,  6, 74, 85, 18,  9, 83, 30,  9, 41, 73, 73, 18,  4,\n",
       "       66, 45, 83, 45, 73, 85, 84, 72, 78, 85, 30, 83, 89, 74, 85, 83, 66,\n",
       "       87,  9, 66, 41, 33, 78, 85, 45, 83, 89, 74, 87, 89, 83,  9, 41, 45,\n",
       "       85, 83, 89, 35, 85, 78, 68, 85, 83, 81, 85, 85, 89, 83, 89, 87, 78,\n",
       "       78, 83, 41,  4, 83, 85, 18, 89, 74, 85,  9, 83, 45, 18, 30, 85, 83,\n",
       "       41, 81, 83, 74, 18, 56, 32, 83, 87, 83, 74, 85, 78, 78, 74])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = tuple(set(text)) # drop duplicates\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch: i for i, ch in int2char.items()}\n",
    "encoded = np.array([char2int[ch] for ch in text[2002:]]) # Number Encoding of Characters\n",
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T10:39:01.529920Z",
     "iopub.status.busy": "2020-09-01T10:39:01.529249Z",
     "iopub.status.idle": "2020-09-01T10:39:01.531980Z",
     "shell.execute_reply": "2020-09-01T10:39:01.532425Z"
    },
    "papermill": {
     "duration": 0.020814,
     "end_time": "2020-09-01T10:39:01.532541",
     "exception": false,
     "start_time": "2020-09-01T10:39:01.511727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_hot(arr, n_labels):\n",
    "    res = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
    "    res[np.arange(res.shape[0]), arr.flatten()]=1\n",
    "    res = res.reshape((*arr.shape, n_labels))\n",
    "    return res\n",
    "\n",
    "def get_batch(arr, batch_size, seq_length):\n",
    "    n_batches = len(arr) // (batch_size*seq_length)\n",
    "    arr = arr[:n_batches*batch_size*seq_length] # So that it divides to zero\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    for i in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, i:i+seq_length]\n",
    "        y = np.zeros_like(x) # Labels: the next character\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, i+seq_length]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T10:39:01.550141Z",
     "iopub.status.busy": "2020-09-01T10:39:01.549393Z",
     "iopub.status.idle": "2020-09-01T10:39:01.552910Z",
     "shell.execute_reply": "2020-09-01T10:39:01.553385Z"
    },
    "papermill": {
     "duration": 0.015765,
     "end_time": "2020-09-01T10:39:01.553494",
     "exception": false,
     "start_time": "2020-09-01T10:39:01.537729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([74, 89, 47, 83,  6, 74, 85, 18,  9, 83, 30,  9, 41, 73, 73, 18,  4,\n",
       "        66, 45, 83, 45, 73, 85, 84, 72, 78, 85, 30, 83, 89, 74, 85, 83, 66,\n",
       "        87,  9, 66, 41, 33, 78, 85, 45, 83, 89, 74, 87, 89, 83,  9, 41]),\n",
       " array([89, 47, 83,  6, 74, 85, 18,  9, 83, 30,  9, 41, 73, 73, 18,  4, 66,\n",
       "        45, 83, 45, 73, 85, 84, 72, 78, 85, 30, 83, 89, 74, 85, 83, 66, 87,\n",
       "         9, 66, 41, 33, 78, 85, 45, 83, 89, 74, 87, 89, 83,  9, 41, 45]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = get_batch(encoded, 8, 50)\n",
    "x, y = next(batches)\n",
    "x[0], y[0] # Note that y values are shifted"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.005083,
     "end_time": "2020-09-01T10:39:01.564030",
     "exception": false,
     "start_time": "2020-09-01T10:39:01.558947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T10:39:01.590479Z",
     "iopub.status.busy": "2020-09-01T10:39:01.587668Z",
     "iopub.status.idle": "2020-09-01T10:39:01.593020Z",
     "shell.execute_reply": "2020-09-01T10:39:01.592547Z"
    },
    "papermill": {
     "duration": 0.023648,
     "end_time": "2020-09-01T10:39:01.593122",
     "exception": false,
     "start_time": "2020-09-01T10:39:01.569474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, tokens, n_hiddens, n_layers, drop, lr):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.char = tokens\n",
    "        self.n_hiddens = n_hiddens\n",
    "        self.n_layers = n_layers\n",
    "        self.drop = drop\n",
    "        self.lr = lr\n",
    "        self.int2char = dict(enumerate(self.char))\n",
    "        self.char2int = {ch: i for i, ch in self.int2char.items()}\n",
    "        \n",
    "        self.LSTM = nn.LSTM(len(tokens), n_hiddens, n_layers, dropout=drop, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.fc = nn.Linear(n_hiddens, len(self.char))\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output, hidden = self.LSTM(x, hidden)\n",
    "        output = self.dropout(output)\n",
    "        output = output.contiguous().view(-1, self.n_hiddens)\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        if cuda:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hiddens).zero_().cuda(),\n",
    "                     weight.new(self.n_layers, batch_size, self.n_hiddens).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hiddens).zero_(),\n",
    "                     weight.new(self.n_layers, batch_size, self.n_hiddens).zero_())\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.005132,
     "end_time": "2020-09-01T10:39:01.603587",
     "exception": false,
     "start_time": "2020-09-01T10:39:01.598455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T10:39:01.635580Z",
     "iopub.status.busy": "2020-09-01T10:39:01.627054Z",
     "iopub.status.idle": "2020-09-01T10:57:41.311132Z",
     "shell.execute_reply": "2020-09-01T10:57:41.312030Z"
    },
    "papermill": {
     "duration": 1119.703251,
     "end_time": "2020-09-01T10:57:41.312263",
     "exception": false,
     "start_time": "2020-09-01T10:39:01.609012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30\n",
      "Training Loss: 1323.895\n",
      "Validation Loss: 454.995\n",
      "Validation Loss dropped from inf ---> 454.995. Model Saved.\n",
      "Epoch: 2/30\n",
      "Training Loss: 972.324\n",
      "Validation Loss: 384.465\n",
      "Validation Loss dropped from 454.995 ---> 384.465. Model Saved.\n",
      "Epoch: 3/30\n",
      "Training Loss: 855.715\n",
      "Validation Loss: 350.200\n",
      "Validation Loss dropped from 384.465 ---> 350.200. Model Saved.\n",
      "Epoch: 4/30\n",
      "Training Loss: 792.925\n",
      "Validation Loss: 330.727\n",
      "Validation Loss dropped from 350.200 ---> 330.727. Model Saved.\n",
      "Epoch: 5/30\n",
      "Training Loss: 754.615\n",
      "Validation Loss: 318.541\n",
      "Validation Loss dropped from 330.727 ---> 318.541. Model Saved.\n",
      "Epoch: 6/30\n",
      "Training Loss: 728.598\n",
      "Validation Loss: 309.771\n",
      "Validation Loss dropped from 318.541 ---> 309.771. Model Saved.\n",
      "Epoch: 7/30\n",
      "Training Loss: 709.831\n",
      "Validation Loss: 303.452\n",
      "Validation Loss dropped from 309.771 ---> 303.452. Model Saved.\n",
      "Epoch: 8/30\n",
      "Training Loss: 695.377\n",
      "Validation Loss: 298.471\n",
      "Validation Loss dropped from 303.452 ---> 298.471. Model Saved.\n",
      "Epoch: 9/30\n",
      "Training Loss: 684.100\n",
      "Validation Loss: 294.648\n",
      "Validation Loss dropped from 298.471 ---> 294.648. Model Saved.\n",
      "Epoch: 10/30\n",
      "Training Loss: 674.456\n",
      "Validation Loss: 291.499\n",
      "Validation Loss dropped from 294.648 ---> 291.499. Model Saved.\n",
      "Epoch: 11/30\n",
      "Training Loss: 666.548\n",
      "Validation Loss: 288.631\n",
      "Validation Loss dropped from 291.499 ---> 288.631. Model Saved.\n",
      "Epoch: 12/30\n",
      "Training Loss: 660.023\n",
      "Validation Loss: 286.420\n",
      "Validation Loss dropped from 288.631 ---> 286.420. Model Saved.\n",
      "Epoch: 13/30\n",
      "Training Loss: 653.898\n",
      "Validation Loss: 284.592\n",
      "Validation Loss dropped from 286.420 ---> 284.592. Model Saved.\n",
      "Epoch: 14/30\n",
      "Training Loss: 648.855\n",
      "Validation Loss: 282.820\n",
      "Validation Loss dropped from 284.592 ---> 282.820. Model Saved.\n",
      "Epoch: 15/30\n",
      "Training Loss: 644.281\n",
      "Validation Loss: 281.345\n",
      "Validation Loss dropped from 282.820 ---> 281.345. Model Saved.\n",
      "Epoch: 16/30\n",
      "Training Loss: 640.159\n",
      "Validation Loss: 280.366\n",
      "Validation Loss dropped from 281.345 ---> 280.366. Model Saved.\n",
      "Epoch: 17/30\n",
      "Training Loss: 636.480\n",
      "Validation Loss: 279.195\n",
      "Validation Loss dropped from 280.366 ---> 279.195. Model Saved.\n",
      "Epoch: 18/30\n",
      "Training Loss: 632.941\n",
      "Validation Loss: 278.018\n",
      "Validation Loss dropped from 279.195 ---> 278.018. Model Saved.\n",
      "Epoch: 19/30\n",
      "Training Loss: 629.829\n",
      "Validation Loss: 277.212\n",
      "Validation Loss dropped from 278.018 ---> 277.212. Model Saved.\n",
      "Epoch: 20/30\n",
      "Training Loss: 626.730\n",
      "Validation Loss: 276.383\n",
      "Validation Loss dropped from 277.212 ---> 276.383. Model Saved.\n",
      "Epoch: 21/30\n",
      "Training Loss: 623.869\n",
      "Validation Loss: 275.726\n",
      "Validation Loss dropped from 276.383 ---> 275.726. Model Saved.\n",
      "Epoch: 22/30\n",
      "Training Loss: 621.559\n",
      "Validation Loss: 274.997\n",
      "Validation Loss dropped from 275.726 ---> 274.997. Model Saved.\n",
      "Epoch: 23/30\n",
      "Training Loss: 619.205\n",
      "Validation Loss: 274.345\n",
      "Validation Loss dropped from 274.997 ---> 274.345. Model Saved.\n",
      "Epoch: 24/30\n",
      "Training Loss: 617.042\n",
      "Validation Loss: 273.571\n",
      "Validation Loss dropped from 274.345 ---> 273.571. Model Saved.\n",
      "Epoch: 25/30\n",
      "Training Loss: 614.723\n",
      "Validation Loss: 273.154\n",
      "Validation Loss dropped from 273.571 ---> 273.154. Model Saved.\n",
      "Epoch: 26/30\n",
      "Training Loss: 612.638\n",
      "Validation Loss: 272.803\n",
      "Validation Loss dropped from 273.154 ---> 272.803. Model Saved.\n",
      "Epoch: 27/30\n",
      "Training Loss: 610.776\n",
      "Validation Loss: 272.576\n",
      "Validation Loss dropped from 272.803 ---> 272.576. Model Saved.\n",
      "Epoch: 28/30\n",
      "Training Loss: 608.872\n",
      "Validation Loss: 272.332\n",
      "Validation Loss dropped from 272.576 ---> 272.332. Model Saved.\n",
      "Epoch: 29/30\n",
      "Training Loss: 607.277\n",
      "Validation Loss: 271.845\n",
      "Validation Loss dropped from 272.332 ---> 271.845. Model Saved.\n",
      "Epoch: 30/30\n",
      "Training Loss: 605.888\n",
      "Validation Loss: 271.207\n",
      "Validation Loss dropped from 271.845 ---> 271.207. Model Saved.\n"
     ]
    }
   ],
   "source": [
    "# ---------------\n",
    "# Hyperparams\n",
    "# ---------------\n",
    "\n",
    "n_hiddens = 512\n",
    "n_layers = 2\n",
    "batch_size = 128\n",
    "seq_length = 100\n",
    "n_epochs = 30\n",
    "drop = 0.5\n",
    "lr = 0.001\n",
    "clip = 5\n",
    "\n",
    "model = LSTM(chars, n_hiddens, n_layers, drop, lr)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "validation = 0.3\n",
    "val_idx = int(len(encoded)*(1-validation))\n",
    "train, valid = encoded[:val_idx], encoded[val_idx:]\n",
    "\n",
    "val_loss_def = np.Inf\n",
    "tra_losses=[]\n",
    "val_losses=[]\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    tra_loss, val_loss = 0,0\n",
    "    \n",
    "    h = model.init_hidden(batch_size)\n",
    "    \n",
    "    for x, y in get_batch(train, batch_size, seq_length):\n",
    "        x = one_hot(x, len(chars))\n",
    "        x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        h = tuple([_.data for _ in h])\n",
    "        model.zero_grad()\n",
    "        output, h = model(x, h)\n",
    "        loss = criterion(output, y.view(-1).long())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        tra_loss += loss.item()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        h = model.init_hidden(batch_size)\n",
    "        for x,y in get_batch(valid, batch_size, seq_length):\n",
    "            x = one_hot(x, len(chars))\n",
    "            x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            if cuda:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "            h = tuple([_.data for _ in h])\n",
    "            model.zero_grad()\n",
    "            output, h = model(x, h)\n",
    "            loss = criterion(output, y.view(-1).long())\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    tra_losses.append(tra_loss)\n",
    "    val_losses.append(val_loss)\n",
    "            \n",
    "    print(\"Epoch: {}/{}\".format(epoch+1, n_epochs))\n",
    "    print(\"Training Loss: {:.3f}\".format(tra_loss))\n",
    "    print(\"Validation Loss: {:.3f}\".format(val_loss))\n",
    "    if val_loss < val_loss_def:\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(\"Validation Loss dropped from {:.3f} ---> {:.3f}. Model Saved.\".format(val_loss_def, val_loss))\n",
    "        val_loss_def = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T10:57:41.342353Z",
     "iopub.status.busy": "2020-09-01T10:57:41.341741Z",
     "iopub.status.idle": "2020-09-01T10:57:41.355024Z",
     "shell.execute_reply": "2020-09-01T10:57:41.354499Z"
    },
    "papermill": {
     "duration": 0.035171,
     "end_time": "2020-09-01T10:57:41.355131",
     "exception": false,
     "start_time": "2020-09-01T10:57:41.319960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "def predict(model, chars, h=None, topk=None):\n",
    "    \n",
    "    x = np.array([[model.char2int[chars]]])\n",
    "    x = one_hot(x, len(model.char))\n",
    "    x = torch.from_numpy(x)\n",
    "    if cuda:\n",
    "        x = x.cuda()\n",
    "    h = tuple([_.data for _ in h])\n",
    "    x, h = model(x, h)\n",
    "    p = F.softmax(x, dim=1).data\n",
    "    if cuda:\n",
    "        p = p.cpu()\n",
    "    if topk is None:\n",
    "        top_ch = np.arange(len(model.char))\n",
    "    else:\n",
    "        p, top_ch = p.topk(topk)\n",
    "        top_ch = top_ch.numpy().squeeze()\n",
    "    p = p.numpy().squeeze()\n",
    "    char = np.random.choice(top_ch, p=p/p.sum())\n",
    "    return model.int2char[char], h\n",
    "\n",
    "def sample(model, size, prime, topk):\n",
    "    \n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        chars = [c for c in prime]\n",
    "        h = model.init_hidden(1)\n",
    "        \n",
    "        for c in prime:\n",
    "            r, h = predict(model, c, h, topk)\n",
    "        chars.append(r)\n",
    "        \n",
    "        for i in range(size):\n",
    "            r, h = predict(model, chars[-1], h, topk)\n",
    "            chars.append(r)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T10:57:41.374516Z",
     "iopub.status.busy": "2020-09-01T10:57:41.373851Z",
     "iopub.status.idle": "2020-09-01T10:57:42.318585Z",
     "shell.execute_reply": "2020-09-01T10:57:42.319082Z"
    },
    "papermill": {
     "duration": 0.956971,
     "end_time": "2020-09-01T10:57:42.319215",
     "exception": false,
     "start_time": "2020-09-01T10:57:41.362244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Limble Captor, she’s been seen into the boy of the Smallwood and her strength, and then see her to the wind when she saw him. To the bridge to the stones and the stars on the walk. And the warmth of the Shadow Tower will stay at the fire, as it was, and he couldn’t have them. I wish you was still as worn her to say they.” Haldor the blood was a shadow, but he would have taken the wolf, but inside the sight of their horse, and to truth that the walls were still a head. “Will there arrund that betrate on the walls,” he said. “I will not be a sword of the back of this way to hear that, and I’m a sort of, anounced, that wind are the crow. His lord castle.”“They couldn’t have been a son of the world, though, and I didn’t have to have a sword for a should happen again. If I was stroking him with him.” Hizdahr word him another store. “I will not bear to death to your brother and the storms.”“That’s this,” the sign the other served with a mail and shill while she could see the woods and shaved her little blood. “I would hid who he will say what that would hear out. The sort of man would sail to my father’s skinny man. It makes her strength. This one is so law.”“It’s that morning.”The serving man stood struggling at him, but the wights are wide and finely.“I will not bring them out,” said Tyrost. “It’s a boy of the sea, to be sending me them.”“With your best.” Her eyes were so hard that too late. The sand was true. The stableboar will be the seat as well. They were all that his first '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(model, size=1500, prime='The', topk=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.007118,
     "end_time": "2020-09-01T10:57:42.333880",
     "exception": false,
     "start_time": "2020-09-01T10:57:42.326762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.007629,
     "end_time": "2020-09-01T10:57:42.348766",
     "exception": false,
     "start_time": "2020-09-01T10:57:42.341137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.007011,
     "end_time": "2020-09-01T10:57:42.363013",
     "exception": false,
     "start_time": "2020-09-01T10:57:42.356002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.007085,
     "end_time": "2020-09-01T10:57:42.377334",
     "exception": false,
     "start_time": "2020-09-01T10:57:42.370249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1129.898254,
   "end_time": "2020-09-01T10:57:42.893189",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-01T10:38:52.994935",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
