{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Module Import"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport time\nimport os\nimport glob\nimport PIL\nfrom PIL import Image\nimport itertools\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom torchvision.utils import save_image, make_grid\n\ncuda = torch.cuda.is_available()\n\nif cuda:\n    print(\"Cuda ON\")\nelse:\n    print(\"No GPU...\")","execution_count":1,"outputs":[{"output_type":"stream","text":"Cuda ON\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# 2. Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_rgb(image):\n    rgb_image = Image.new(\"RGB\", image.size)\n    rgb_image.paste(image)\n    return rgb_image\n\nclass ImageDataset(Dataset):\n    def __init__(self, root, transform_, aligned, mode='train'):\n        self.transform = transforms.Compose(transform_)\n        self.aligned = aligned\n        self.files_A = sorted(glob.glob(os.path.join(root, \"{}A\".format(mode)) + \"/*.*\"))\n        self.files_B = sorted(glob.glob(os.path.join(root, \"{}B\".format(mode)) + \"/*.*\"))\n        \n    def __getitem__(self, index):\n        image_A = Image.open(self.files_A[index % len(self.files_A)])\n        \n        if self.aligned:\n            image_B = Image.open(self.files_B[index % len(self.files_B)])\n        else:\n            image_B = Image.open(self.files_B[random.randint(0, len(self.files_B)-1)])\n            \n        if image_A.mode != \"RGB\":\n            image_A = to_rgb(image_A)\n        if image_B.mode != \"RGB\":\n            image_B = to_rgb(image_B)\n            \n        item_A = self.transform(image_A)\n        item_B = self.transform(image_B)\n        \n        return {\"A\": item_A, \"B\": item_B}\n    \n    def __len__(self):\n        return max(len(self.files_A), len(self.files_B))","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Baseline Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def weight_init(m):\n    classname = m.__class__.__name__\n    if classname.find(\"Conv\") != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n        if hasattr(m, 'bias') and m.bias is not None:\n            torch.nn.init.constant_(m.bias.data, 0.0)\n    elif classname.find(\"BatchNorm2d\") != -1:\n        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n        torch.nn.init.constant_(m.bias.data, 0.0)\n        \nclass residual_block(nn.Module):\n    def __init__(self, in_features):\n        super(residual_block, self).__init__()\n        \n        self.block = nn.Sequential(\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features)\n        )\n        \n    def forward(self, x):\n        return x + self.block(x)\n    \nclass GeneratorResnet(nn.Module):\n    def __init__(self, input_shape, num_residual_blocks):\n        super(GeneratorResnet, self).__init__()\n        \n        channels = input_shape[0]\n        out_features = 64\n        \n        model = [\n            nn.ReflectionPad2d(channels),\n            nn.Conv2d(channels, out_features, 7),\n            nn.InstanceNorm2d(out_features),\n            nn.ReLU(inplace=True)\n        ]\n        \n        # DownSample\n        for _ in range(2):\n            in_features = out_features\n            out_features *= 2\n            model += [\n                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True)\n            ]\n            \n        # Residual Blocks for 128 x 128 // for 256x256 or higher, use 9 such blocks\n        for _ in range(num_residual_blocks):\n            model += [residual_block(out_features)]\n            \n        # Upsample\n        for _ in range(2):\n            in_features = out_features\n            out_features //= 2\n            model += [\n                nn.Upsample(scale_factor=2),\n                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True)\n            ]\n            \n        # Output Layer\n        model += [\n            nn.ReflectionPad2d(channels),\n            nn.Conv2d(out_features, channels, 7),\n            nn.InstanceNorm2d(channels),\n            nn.Tanh()\n        ]\n        \n        self.model = nn.Sequential(*model)\n        \n    def forward(self, x):\n        return self.model(x)\n    \nclass Discriminator(nn.Module):\n    def __init__(self, input_shape):\n        super(Discriminator, self).__init__()\n        out_features, (channels, height, width) = 64, input_shape\n        self.output_shape = (1, height // 2**4, width // 2**4)\n        model = [\n            nn.Conv2d(channels, out_features, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True)\n        ]\n        \n        for _ in range(3):\n            in_features = out_features\n            out_features *= 2\n            model += [\n                nn.Conv2d(in_features, out_features, 4, stride=2, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.LeakyReLU(0.2, inplace=True)\n            ]\n            \n        model += [nn.ZeroPad2d((1,0,1,0))]\n        model += [nn.Conv2d(out_features, 1, 4, padding=1)]\n        \n        self.model = nn.Sequential(*model)\n        \n    def forward(self, x):\n        return self.model(x)","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LambdaLR:\n    def __init__(self, n_epochs, offset, decay_start_epoch):\n        self.n_epochs = n_epochs\n        self.offset = offset\n        self.decay_start_epoch = decay_start_epoch\n    \n    def step(self, epoch):\n        return 1.0 - max(0, epoch+self.offset-self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ReplayBuffer:\n    def __init__(self, max_size=50):\n        assert max_size > 0, \"Empty Buffer Not Allowed\"\n        self.max_size = max_size\n        self.data = []\n        \n    def push_pop(self, data):\n        to_return = []\n        for element in data.data:\n            element = torch.unsqueeze(element, 0)\n            if len(self.data) < self.max_size:\n                self.data.append(element)\n                to_return.append(element)\n            else:\n                if random.uniform(0,1) > 0.5:\n                    i = random.randint(0, self.max_size-1)\n                    to_return.append(self.data[i].clone())\n                    self.data[i] = element\n                else:\n                    to_return.append(element)\n        return Variable(torch.cat(to_return))","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Compile Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile Loss Functions\ncriterion_GAN = nn.MSELoss()\ncriterion_cycle = nn.L1Loss()\ncriterion_identity = nn.L1Loss()\n\nimg = np.asarray(Image.open('/kaggle/input/monet2photo/monet2photo/trainA/0.jpg')) # Hardcoded for Kaggle Kernel\ninput_shape = (img.shape[2], img.shape[0], img.shape[1])\n\nG_AB = GeneratorResnet(input_shape, num_residual_blocks=9)\nG_BA = GeneratorResnet(input_shape, num_residual_blocks=9)\nD_A = Discriminator(input_shape)\nD_B = Discriminator(input_shape)\n\nif cuda:\n    G_AB, G_BA, D_A, D_B = G_AB.cuda(), G_BA.cuda(), D_A.cuda(), D_B.cuda()\n    criterion_GAN, criterion_cycle, criterion_identity = criterion_GAN.cuda(), criterion_cycle.cuda(), criterion_identity.cuda()\n    \nG_AB.apply(weight_init)\nG_BA.apply(weight_init)\nD_A.apply(weight_init)\nD_B.apply(weight_init)\n\n# ------------ #\n#  Hyperparams\n# ------------ #\n\nlr = 0.0002\nbeta1, beta2 = 0.5, 0.999\nn_epochs = 200\nepoch = 0\ndecay_epoch = 100\n\noptimizer_G = optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(beta1, beta2))\noptimizer_DA = optim.Adam(D_A.parameters(), lr=lr, betas=(beta1, beta2))\noptimizer_DB = optim.Adam(D_B.parameters(), lr=lr, betas=(beta1, beta2))\n\nlr_scheduler_G = optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\nlr_scheduler_DA = optim.lr_scheduler.LambdaLR(optimizer_DA, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\nlr_scheduler_DB = optim.lr_scheduler.LambdaLR(optimizer_DB, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n\nTensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n\nfakeA_buffer = ReplayBuffer()\nfakeB_buffer = ReplayBuffer()\n\ntransform_ = [\n    transforms.Resize(int(input_shape[1]*1.12), Image.BICUBIC),\n    transforms.RandomCrop((input_shape[1], input_shape[2])),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n]\n\ntrainloader = DataLoader(\n    ImageDataset(\"/kaggle/input/monet2photo/monet2photo/\", transform_=transform_, aligned=False, mode='train'),\n    batch_size = 1,\n    shuffle=True\n)\n\n# validloader = DataLoader(\n#     ImageDataset(\"/kaggle/input/monet2photo/monet2photo/\", transform_=transform_, aligned=False, mode='test'),\n#     batch_size=1,\n#     shuffle=True\n# )","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sample_image(finished_batch):\n    imgs = next(iter(validloader))\n    G_AB.eval()\n    G_BA.eval()\n    real_A = Variable(imgs['A'].type(Tensor))\n    real_B = Variable(imgs['B'].type(Tensor))\n    fake_A = G_BA(real_B)\n    fake_B = G_AB(real_A)\n    real_A = make_grid(real_A, nrow=5, normalize=True)\n    real_B = make_grid(real_B, nrow=5, normalize=True)\n    fake_A = make_grid(fake_A, nrow=5, normalize=True)\n    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n    image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n    save_image(image_grid, \"images/%s.png\" % finished_batch, normalize=False)\n","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nt0 = time.time()\noutput = defaultdict(list)\n\nfor epoch in range(n_epochs):\n    for i, batch in enumerate(trainloader):\n        \n        real_A = Variable(batch['A'].type(Tensor))\n        real_B = Variable(batch['B'].type(Tensor))\n        \n        t = Variable(Tensor(np.ones((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n        f = Variable(Tensor(np.zeros((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n        \n        # --------------- #\n        # Train Generator\n        # --------------- #\n        \n        optimizer_G.zero_grad()\n        G_AB.train()\n        G_BA.train()\n        \n        # Identity Loss\n        loss_id_A = criterion_identity(G_BA(real_A), real_A)\n        loss_id_B = criterion_identity(G_AB(real_B), real_B)\n        \n        loss_identity = (loss_id_A + loss_id_B) / 2\n        \n        fake_A, fake_B = G_BA(real_B), G_AB(real_A)\n        \n        # GAN Loss\n        loss_GAN_AB = criterion_GAN(D_B(fake_B), t)\n        loss_GAN_BA = criterion_GAN(D_A(fake_A), t)\n        \n        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n        \n        # Cycle-consistency Loss\n        loss_cycle_A = criterion_cycle(G_BA(fake_B), real_A)\n        loss_cycle_B = criterion_cycle(G_AB(fake_A), real_B)\n        \n        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n        \n        # Hyperparameters in the literature\n        loss_G = 5*loss_identity + 10*loss_cycle + loss_GAN\n        \n        loss_G.backward()\n        optimizer_G.step()\n        \n        # ------------------- #\n        # Train Discriminator\n        # ------------------- #\n        \n        G_AB.eval()\n        G_BA.eval()\n        \n        optimizer_DA.zero_grad()\n        \n        loss_real_DA = criterion_GAN(D_A(real_A), t)\n        fake_A = fakeA_buffer.push_pop(fake_A)\n        loss_fake_DA = criterion_GAN(D_A(fake_A), f)\n        loss_DA = (loss_real_DA + loss_fake_DA) / 2\n        loss_DA.backward()\n        optimizer_DA.step()\n        \n        optimizer_DB.zero_grad()\n        \n        loss_real_DB = criterion_GAN(D_B(real_B), t)\n        fake_B = fakeB_buffer.push_pop(fake_B)\n        loss_fake_DB = criterion_GAN(D_B(fake_B), f)\n        loss_DB = (loss_real_DB + loss_fake_DB) / 2\n        loss_DB.backward()\n        optimizer_DB.step()\n        \n        loss_D = (loss_DA + loss_DB) / 2\n        \n    t1 = time.time()\n    \n    output['epoch'].append(epoch+1)\n    output['Loss_G'].append(loss_G.item())\n    output['Loss_D'].append(loss_D.item())\n    output['Loss_id'].append(loss_identity.item())\n    output['Loss_GAN'].append(loss_GAN.item())\n    output['Loss_cycle'].append(loss_cycle.item())\n    \n    print(\"Epoch: {}\".format(epoch+1))\n    print(\"Time per Epoch: {:.1f}m\".format((t1-t0)/60))\n    print(\"Generator Loss: {:.3f}\".format(loss_G.item()))\n    print(\"Discriminator Loss: {:.3f}\".format(loss_D.item()))\n    print(\"Identity Loss: {:.3f}\".format(loss_identity.item()))\n    print(\"GAN Loss: {:.3f}\".format(loss_GAN.item()))\n    print(\"Cycle Loss: {:.3f}\".format(loss_cycle.item()))\n    print('-'*50)","execution_count":8,"outputs":[{"output_type":"stream","text":"Epoch: 1\nTime per Epoch: 40.3m\nGenerator Loss: 3.453\nDiscriminator Loss: 0.123\nIdentity Loss: 0.138\nGAN Loss: 1.160\nCycle Loss: 0.160\n--------------------------------------------------\nEpoch: 2\nTime per Epoch: 80.4m\nGenerator Loss: 2.971\nDiscriminator Loss: 0.188\nIdentity Loss: 0.128\nGAN Loss: 0.899\nCycle Loss: 0.143\n--------------------------------------------------\nEpoch: 3\nTime per Epoch: 120.5m\nGenerator Loss: 2.729\nDiscriminator Loss: 0.064\nIdentity Loss: 0.126\nGAN Loss: 0.877\nCycle Loss: 0.122\n--------------------------------------------------\nEpoch: 4\nTime per Epoch: 160.6m\nGenerator Loss: 2.314\nDiscriminator Loss: 0.191\nIdentity Loss: 0.117\nGAN Loss: 0.502\nCycle Loss: 0.123\n--------------------------------------------------\nEpoch: 5\nTime per Epoch: 200.7m\nGenerator Loss: 2.034\nDiscriminator Loss: 0.111\nIdentity Loss: 0.112\nGAN Loss: 0.478\nCycle Loss: 0.100\n--------------------------------------------------\nEpoch: 6\nTime per Epoch: 240.8m\nGenerator Loss: 3.870\nDiscriminator Loss: 0.024\nIdentity Loss: 0.203\nGAN Loss: 0.763\nCycle Loss: 0.209\n--------------------------------------------------\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-800cdf5d17d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mloss_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss_identity\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss_cycle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_GAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mloss_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}