{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Import"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nimport random\nimport time\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom bs4 import BeautifulSoup\n\ncuda = torch.cuda.is_available()\nif cuda:\n    print(\"Cuda Available\")\nelse:\n    print(\"No Cuda\")","execution_count":1,"outputs":[{"output_type":"stream","text":"Cuda Available\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndf.head(3)","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# 2. Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sentiment'] = df.sentiment.apply(lambda x: int(x=='positive'))\ndf = df.sample(frac=1).reset_index(drop=True)\ndf['kfold'] = [1,2,3,4,5]*10000\ndf.head(3)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                                              review  sentiment  kfold\n0  Alright, I'm 12, so this is where you get to s...          1      1\n1  for my opinion, the middle of the film, specia...          1      2\n2  In post civil war America the President, (Van ...          1      3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alright, I'm 12, so this is where you get to s...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>for my opinion, the middle of the film, specia...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>In post civil war America the President, (Van ...</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def html_parse(text):\n    soup = BeautifulSoup(text, 'html.parser')\n    return soup.get_text()\n\ndef remove_stopwords(text):\n    tokens = word_tokenize(text)\n    stop = stopwords.words('english')\n    return [token for token in tokens if token.lower() not in stop]\n\ndef lemmatize(text):\n    lemmatizer = WordNetLemmatizer()\n    return [lemmatizer.lemmatize(word) for word in text]\n\ndef erase_mark(text):\n    return text.replace('!', '').replace('?', '').replace(\"'\", \"\").replace('\"', '').replace(',', '').replace('.', '')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = time.time()\ndf.review = df.review.apply(html_parse).apply(erase_mark).apply(remove_stopwords).apply(lemmatize)\nt1 = time.time()\nprint(\"Duration: {:.1f}M\".format((t1-t0)/60))\ndf.head()","execution_count":5,"outputs":[{"output_type":"stream","text":"Duration: 3.0M\n","name":"stdout"},{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"                                              review  sentiment  kfold\n0  [Alright, Im, 12, get, see, movie, pre-teens, ...          1      1\n1  [opinion, middle, film, specially, love, scene...          1      2\n2  [post, civil, war, America, President, (, Van,...          1      3\n3  [thought, get, heart, film, :, 1, ), never, se...          1      4\n4  [Vow, Cherish, wonderful, movie, based, novel,...          1      5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[Alright, Im, 12, get, see, movie, pre-teens, ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[opinion, middle, film, specially, love, scene...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[post, civil, war, America, President, (, Van,...</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[thought, get, heart, film, :, 1, ), never, se...</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[Vow, Cherish, wonderful, movie, based, novel,...</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def int2char(text):\n    return dict(enumerate(text))\ndef char2int(text):\n    return {ch: i for i, ch in int2char(text).items()}\nchars = []\nfor i, v in df.iterrows():\n    chars += v['review']\nchars = tuple(set(chars))\ni2c = int2char(chars)\nc2i = char2int(chars)","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Pretrained Word Embeddings"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"import codecs\nimport tqdm\n\nfasttext = {}\nf = codecs.open('../input/fasttext/wiki.simple.vec', encoding='utf-8')\nfor line in f:\n    values = line.rstrip().rsplit(' ')\n    word = values[0]\n    vec = np.asarray(values[1:], dtype=np.float32)\n    fasttext[word]=vec\nf.close()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_emb_matrix(dic, embedding_dict, dim):\n    embedding_matrix = np.zeros((len(dic)+1, dim))\n    for i, v in dic.items():\n        if v in embedding_dict:\n            embedding_matrix[i] = embedding_dict[v]\n    return embedding_matrix\n            \nembedding_matrix = create_emb_matrix(i2c, fasttext, 300)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"class IMDB(Dataset):\n    def __init__(self, review, sentiment):\n        self.review = review\n        self.sentiment = sentiment\n        \n    def __getitem__(self, index):\n        return {'review': torch.LongTensor(self.review[index]), 'sentiment': torch.LongTensor([self.sentiment[index]])}\n    \n    def __len__(self):\n        return len(self.sentiment)\n    \nclass LSTM(nn.Module):\n    def __init__(self, embedding_matrix):\n        super(LSTM, self).__init__()\n        num_words = embedding_matrix.shape[0]\n        emb_dim = embedding_matrix.shape[1]\n        self.embedding = nn.Embedding(num_embeddings=num_words, embedding_dim=emb_dim)\n        self.embedding.weight = nn.Parameter(torch.FloatTensor(embedding_matrix))\n        self.embedding.weight.requires_grad = False\n        \n        self.lstm = nn.LSTM(emb_dim, 256, 2, bidirectional=True, batch_first=True)\n        self.fc1 = nn.Linear(1024, 1)\n#         self.fc2 = nn.Linear(32, 1)\n        \n    def forward(self, x):\n        x = self.embedding(x)\n        hidden, _ = self.lstm(x)\n        avg_pool = torch.mean(hidden, 1)\n        max_pool, max_idx = torch.max(hidden, 1)\n        out = torch.cat((avg_pool, max_pool), 1)\n        out = self.fc1(out)\n        return F.sigmoid(out)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(yhat, y):\n    return torch.sum((yhat>0.5)==y).item()/len(y)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def char2idx(list_):\n    return [c2i[ch] for ch in list_]\n    \ndf['length'] = df.review.apply(len)\ndf = df[df['length']>4]\ndf.review = df.review.apply(char2idx)\ndf.review = df.review.apply(np.array)\n\ndf.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"                                              review  sentiment  kfold  length\n0  [155296, 217473, 127720, 173521, 107818, 65254...          1      1      84\n1  [186398, 185476, 88682, 250, 190031, 225370, 1...          1      2      30\n2  [160240, 221405, 212517, 220262, 143263, 192, ...          1      3     107\n3  [166688, 173521, 5227, 88682, 207637, 172513, ...          1      4     171\n4  [53165, 206747, 8554, 65254, 161573, 176195, 3...          1      5      61","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>kfold</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[155296, 217473, 127720, 173521, 107818, 65254...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[186398, 185476, 88682, 250, 190031, 225370, 1...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[160240, 221405, 212517, 220262, 143263, 192, ...</td>\n      <td>1</td>\n      <td>3</td>\n      <td>107</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[166688, 173521, 5227, 88682, 207637, 172513, ...</td>\n      <td>1</td>\n      <td>4</td>\n      <td>171</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[53165, 206747, 8554, 65254, 161573, 176195, 3...</td>\n      <td>1</td>\n      <td>5</td>\n      <td>61</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LSTM(embedding_matrix)\nif cuda:\n    model.cuda()","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\n    \nepochs=5\nlr = 0.002\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.BCELoss()\n\n\nfor fold in range(1,6):\n    train, valid = df[df['kfold']!=fold].reset_index(drop=True), df[df['kfold']==fold].reset_index(drop=True)\n    \n    xtrain, xtest = train.review.values, valid.review.values\n    \n    xtrain = pad_sequences(xtrain, maxlen=1447)\n    xtest = pad_sequences(xtest, maxlen=1447)\n    \n#     print(xtrain[0].shape, train.sentiment.values.shape)\n#     print(xtrain[0], y[0])\n    \n    train_dset = IMDB(xtrain, train.sentiment.values)\n    valid_dset = IMDB(xtest, valid.sentiment.values)\n    trainloader = DataLoader(train_dset, batch_size=128, shuffle=True)\n    validloader = DataLoader(valid_dset, batch_size=128, shuffle=True)\n    \n    for epoch in range(epochs):\n        \n        train_loss, valid_loss = 0, 0\n        train_accuracy, valid_accuracy = 0,0\n        \n        for batch in trainloader:\n            optimizer.zero_grad()\n            x, y = batch['review'], batch['sentiment']\n            if cuda:\n                x, y = x.cuda(), y.cuda().float()\n            output = model(x)\n            train_accuracy += accuracy(output.cpu().detach(), y.cpu().detach())\n            loss = criterion(output, y)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n        \n        with torch.no_grad():\n            for batch in validloader:\n                x, y = batch['review'], batch['sentiment']\n                if cuda:\n                    x, y = x.cuda(), y.cuda().float()\n                output = model(x)\n                loss = criterion(output, y)\n                valid_loss += loss.item()\n                valid_accuracy += accuracy(output.cpu().detach(), y.cpu().detach())\n        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n        print(\"Train Acc: {:.2f}%\".format(100*train_accuracy/len(trainloader)))\n        print(\"Valid Acc: {:.2f}%\".format(100*valid_accuracy/len(validloader)))","execution_count":15,"outputs":[{"output_type":"stream","text":"Epoch: 1/5\nTrain Acc: 77.62%\nValid Acc: 84.46%\nEpoch: 2/5\nTrain Acc: 84.84%\nValid Acc: 85.02%\nEpoch: 3/5\nTrain Acc: 87.13%\nValid Acc: 86.64%\nEpoch: 4/5\nTrain Acc: 89.00%\nValid Acc: 87.19%\nEpoch: 5/5\nTrain Acc: 91.01%\nValid Acc: 87.64%\nEpoch: 1/5\nTrain Acc: 91.93%\nValid Acc: 92.94%\nEpoch: 2/5\nTrain Acc: 94.70%\nValid Acc: 92.88%\nEpoch: 3/5\nTrain Acc: 97.10%\nValid Acc: 92.00%\nEpoch: 4/5\nTrain Acc: 98.73%\nValid Acc: 91.64%\nEpoch: 5/5\nTrain Acc: 99.54%\nValid Acc: 92.02%\nEpoch: 1/5\nTrain Acc: 96.54%\nValid Acc: 99.01%\nEpoch: 2/5\nTrain Acc: 99.26%\nValid Acc: 99.00%\nEpoch: 3/5\nTrain Acc: 99.87%\nValid Acc: 98.59%\nEpoch: 4/5\nTrain Acc: 99.98%\nValid Acc: 99.21%\nEpoch: 5/5\nTrain Acc: 99.99%\nValid Acc: 99.44%\nEpoch: 1/5\nTrain Acc: 98.34%\nValid Acc: 99.06%\nEpoch: 2/5\nTrain Acc: 99.31%\nValid Acc: 99.14%\nEpoch: 3/5\nTrain Acc: 99.74%\nValid Acc: 98.89%\nEpoch: 4/5\nTrain Acc: 99.92%\nValid Acc: 99.36%\nEpoch: 5/5\nTrain Acc: 99.98%\nValid Acc: 99.50%\nEpoch: 1/5\nTrain Acc: 98.77%\nValid Acc: 99.24%\nEpoch: 2/5\nTrain Acc: 99.31%\nValid Acc: 98.52%\nEpoch: 3/5\nTrain Acc: 99.81%\nValid Acc: 99.50%\nEpoch: 4/5\nTrain Acc: 99.95%\nValid Acc: 99.46%\nEpoch: 5/5\nTrain Acc: 99.96%\nValid Acc: 99.63%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}