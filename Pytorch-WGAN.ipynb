{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nfrom torch import nn, optim\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\ndef check_cuda():\n    return \"CUDA ON\" if torch.cuda.is_available() else \"NO CUDA :(\"\n\ncheck_cuda()","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"'CUDA ON'"},"metadata":{}}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\ntrain.shape, test.shape","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"((42000, 785), (28000, 784))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\ndata = np.concatenate((np.array(train)[:,1:], np.array(test)), axis=0) / 255.0\n\nclass MNIST(Dataset):\n    def __init__(self, data, transform):\n        self.data = data\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        if self.transform:\n            return np.asarray(self.transform(self.data[index, ]))\n        else:\n            return np.asarray(self.data[index, ])\n        \n    def __len__(self):\n        return self.data.shape[0]\n    \ndataset = MNIST(data.reshape(-1,28,28), transform=False)\ndataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.main_module = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=100, out_channels=1024, kernel_size=7, stride=1, padding=0),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(True),\n        \n            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(True),\n\n            nn.ConvTranspose2d(in_channels=256, out_channels=1, kernel_size=1, stride=1, padding=0)\n        )\n        \n        self.out = nn.Tanh()\n        \n    def forward(self, x):\n        x = self.main_module(x)\n        x = self.out(x)\n        return x\n    \nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.main_module = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=256, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.2, inplace=True)\n        )\n        \n        self.out = nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=3, stride=1, padding=1)\n        self.l = nn.Linear(4*4, 1)\n        \n    def forward(self, x):\n        x = self.main_module(x)\n        x = self.out(x)\n        x = x.view(-1, 4*4)\n        x = self.l(x)\n        return x","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"G = Generator().cuda()\nD = Discriminator().cuda()\nG_optim = optim.RMSprop(G.parameters(), lr=0.00005)\nD_optim = optim.RMSprop(D.parameters(), lr=0.00005)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nepochs = 100\ncritic_iter = 5\nclamp = 0.01\n\nfor epoch in range(epochs):\n    t0 = time.time()\n    t = torch.FloatTensor([1]).cuda()\n    f = t * (-1)\n    \n    for image in dataloader:\n        image = image.view(-1, 1, 28, 28).float()\n    # Train Critic 5 times per Generator train\n    \n        for p in D.parameters():\n            p.requires_grad = True\n            \n        for d_iter in range(critic_iter):\n\n            D.zero_grad()\n\n            # Weight Clipping\n            for p in D.parameters():\n                p.data.clamp_(-clamp, clamp)\n\n\n            z = torch.randn((64, 100, 1, 1)) # Batch_size 64\n            image = Variable(image.cuda())\n            z = Variable(z.cuda())\n\n            d_loss_real = torch.sum(-D(image) * t)\n#             d_loss_real = \n            d_loss_real.backward()\n\n            fake_image = G(z)\n            d_loss_fake = torch.sum(-D(fake_image) * f)\n#             d_loss_fake = d_loss_fake.mean(0).view(1)\n            d_loss_fake.backward()\n\n            d_loss = d_loss_real + d_loss_fake\n            wasserstein_d = d_loss_real - d_loss_fake\n            D_optim.step()\n\n            # Training Generator\n        for p in D.parameters():\n            p.requires_grad = False\n\n        G.zero_grad()\n\n        z = Variable(torch.randn((64, 100, 1, 1)).cuda())\n        fake_image = G(z)\n        g_loss = torch.sum(D(fake_image) * f)\n#         g_loss = g_loss.mean().mean(0).view(1)\n        g_loss.backward()\n        g_cost = -g_loss\n        G_optim.step()\n        \n    t1 = time.time()\n    \n    print(\"Current Epoch: {}\".format(epoch+1))\n    print(\"Time Spent: {:.1f}s\".format(t1-t0))\n    print(\"Critic Loss: {:.3f}\".format(d_loss.item()))\n    print(\"Generator Loss: {:.3f}\".format(g_loss.item()))\n    print()","execution_count":6,"outputs":[{"output_type":"stream","text":"Current Epoch: 1\nTime Spent: 712.5s\nCritic Loss: -8.331\nGenerator Loss: 4.093\n\nCurrent Epoch: 2\nTime Spent: 711.6s\nCritic Loss: -8.080\nGenerator Loss: 4.150\n\nCurrent Epoch: 3\nTime Spent: 711.5s\nCritic Loss: -8.089\nGenerator Loss: 4.098\n\nCurrent Epoch: 4\nTime Spent: 711.6s\nCritic Loss: -8.231\nGenerator Loss: 4.044\n\nCurrent Epoch: 5\nTime Spent: 711.6s\nCritic Loss: -8.086\nGenerator Loss: 4.038\n\nCurrent Epoch: 6\nTime Spent: 710.2s\nCritic Loss: -8.108\nGenerator Loss: 4.142\n\nCurrent Epoch: 7\nTime Spent: 709.8s\nCritic Loss: -8.235\nGenerator Loss: 4.150\n\nCurrent Epoch: 8\nTime Spent: 709.8s\nCritic Loss: -8.122\nGenerator Loss: 4.169\n\nCurrent Epoch: 9\nTime Spent: 709.7s\nCritic Loss: -8.263\nGenerator Loss: 4.168\n\nCurrent Epoch: 10\nTime Spent: 710.2s\nCritic Loss: -8.012\nGenerator Loss: 4.088\n\nCurrent Epoch: 11\nTime Spent: 710.1s\nCritic Loss: -8.107\nGenerator Loss: 4.146\n\nCurrent Epoch: 12\nTime Spent: 710.3s\nCritic Loss: -8.226\nGenerator Loss: 4.118\n\nCurrent Epoch: 13\nTime Spent: 709.9s\nCritic Loss: -8.258\nGenerator Loss: 4.262\n\nCurrent Epoch: 14\nTime Spent: 709.8s\nCritic Loss: -8.035\nGenerator Loss: 4.001\n\nCurrent Epoch: 15\nTime Spent: 710.4s\nCritic Loss: -8.141\nGenerator Loss: 4.186\n\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-46b5c19329bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Batch_size 64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}